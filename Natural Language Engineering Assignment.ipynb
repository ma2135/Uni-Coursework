{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f2S8I2ny-ovS"
   },
   "source": [
    "# NLE Assignment: Sentiment Classification\n",
    "\n",
    "In this assignment, you will be investigating NLP methods for distinguishing positive and negative reviews written about movies.\n",
    "\n",
    "For assessment, you are expected to complete and submit this notebook file.  When answers require code, you may import and use library functions (unless explicitly told otherwise).  All of your own code should be included in the notebook rather than imported from elsewhere.  Written answers should also be included in the notebook.  You should insert as many extra cells as you want and change the type between code and markdown as appropriate.\n",
    "\n",
    "In order to avoid misconduct, you should not talk about the assignment questions with your peers.  If you are not sure what a question is asking you to do or have any other questions, please ask me or one of the Teaching Assistants.\n",
    "\n",
    "Marking guidelines are provided as a separate document.\n",
    "\n",
    "The first few cells contain code to set-up the assignment and bring in some data.   In order to provide unique datasets for analysis by different students, you must enter your candidate number in the following cell.  Otherwise do not change the code in these cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 776,
     "status": "ok",
     "timestamp": 1602225678050,
     "user": {
      "displayName": "Julie Weeds",
      "photoUrl": "",
      "userId": "13844540934373660130"
     },
     "user_tz": -60
    },
    "id": "1gXQAZas-l9c"
   },
   "outputs": [],
   "source": [
    "candidateno=219060 #this MUST be updated to your candidate number so that you get a unique data sample\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "executionInfo": {
     "elapsed": 7200,
     "status": "ok",
     "timestamp": 1602224747300,
     "user": {
      "displayName": "Julie Weeds",
      "photoUrl": "",
      "userId": "13844540934373660130"
     },
     "user_tz": -60
    },
    "id": "nk8JTP88A8vs",
    "outputId": "65e59f95-9e7d-494f-d156-a0428f135fef"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Michael\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Michael\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package movie_reviews to\n",
      "[nltk_data]     C:\\Users\\Michael\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package movie_reviews is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#do not change the code in this cell\n",
    "#preliminary imports\n",
    "\n",
    "#set up nltk\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('movie_reviews')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import movie_reviews\n",
    "\n",
    "#for setting up training and testing data\n",
    "import random\n",
    "\n",
    "#useful other tools\n",
    "import re\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from itertools import zip_longest\n",
    "from nltk.probability import FreqDist\n",
    "from nltk.classify.api import ClassifierI\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 854,
     "status": "ok",
     "timestamp": 1602226177157,
     "user": {
      "displayName": "Julie Weeds",
      "photoUrl": "",
      "userId": "13844540934373660130"
     },
     "user_tz": -60
    },
    "id": "BHBkzAccCVaZ"
   },
   "outputs": [],
   "source": [
    "#do not change the code in this cell\n",
    "def split_data(data, ratio=0.7): # when the second argument is not given, it defaults to 0.7\n",
    "    \"\"\"\n",
    "    Given corpus generator and ratio:\n",
    "     - partitions the corpus into training data and test data, where the proportion in train is ratio,\n",
    "\n",
    "    :param data: A corpus generator.\n",
    "    :param ratio: The proportion of training documents (default 0.7)\n",
    "    :return: a pair (tuple) of lists where the first element of the \n",
    "            pair is a list of the training data and the second is a list of the test data.\n",
    "    \"\"\"\n",
    "    \n",
    "    data = list(data)  \n",
    "    n = len(data)  \n",
    "    train_indices = random.sample(range(n), int(n * ratio))          \n",
    "    test_indices = list(set(range(n)) - set(train_indices))    \n",
    "    train = [data[i] for i in train_indices]           \n",
    "    test = [data[i] for i in test_indices]             \n",
    "    return (train, test)                       \n",
    " \n",
    "\n",
    "def get_train_test_data():\n",
    "    \n",
    "    #get ids of positive and negative movie reviews\n",
    "    pos_review_ids=movie_reviews.fileids('pos')\n",
    "    neg_review_ids=movie_reviews.fileids('neg')\n",
    "   \n",
    "    #split positive and negative data into training and testing sets\n",
    "    pos_train_ids, pos_test_ids = split_data(pos_review_ids)\n",
    "    neg_train_ids, neg_test_ids = split_data(neg_review_ids)\n",
    "    #add labels to the data and concatenate\n",
    "    training = [(movie_reviews.words(f),'pos') for f in pos_train_ids]+[(movie_reviews.words(f),'neg') for f in neg_train_ids]\n",
    "    testing = [(movie_reviews.words(f),'pos') for f in pos_test_ids]+[(movie_reviews.words(f),'neg') for f in neg_test_ids]\n",
    "   \n",
    "    return training, testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1N3LWwBYICPP"
   },
   "source": [
    "When you have run the cell below, your unique training and testing samples will be stored in `training_data` and `testing_data`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 105
    },
    "executionInfo": {
     "elapsed": 17300,
     "status": "ok",
     "timestamp": 1602226420608,
     "user": {
      "displayName": "Julie Weeds",
      "photoUrl": "",
      "userId": "13844540934373660130"
     },
     "user_tz": -60
    },
    "id": "HJLegkdPFUJA",
    "outputId": "b29ea6a9-ea00-4b68-f0cb-ce9e6fa25233"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The amount of training data is 1400\n",
      "The amount of testing data is 600\n",
      "The representation of a single data item is below\n",
      "(['the', 'opening', 'crawl', 'tells', 'us', 'that', ...], 'pos')\n"
     ]
    }
   ],
   "source": [
    "#do not change the code in this cell\n",
    "random.seed(candidateno)\n",
    "training_data,testing_data=get_train_test_data()\n",
    "print(\"The amount of training data is {}\".format(len(training_data)))\n",
    "print(\"The amount of testing data is {}\".format(len(testing_data)))\n",
    "print(\"The representation of a single data item is below\")\n",
    "print(training_data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1)  \n",
    "a) **Generate** a list of 10 content words which are representative of the positive reviews in your training data.\n",
    "\n",
    "b) **Generate** a list of 10 content words which are representative of the negative reviews in your training data.\n",
    "\n",
    "c) **Explain** what you have done and why\n",
    "\n",
    "[20\\%]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Michael\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "from nltk.tokenize import RegexpTokenizer, sent_tokenize, word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "import string\n",
    "from nltk.probability import FreqDist\n",
    "stops = set(stopwords.words('english'))\n",
    "\n",
    "#Takes in a list of words to normalise. All numbers in that list get normalised\n",
    "def numberNormalise (tokenList):\n",
    "    newList = list()\n",
    "    for token in tokenList:\n",
    "        if  token.isdigit(): newList.append(\"NUM\")\n",
    "        else: \n",
    "            for x in token: \n",
    "                if x.isdigit(): \n",
    "                    newList.append(\"Nth\")\n",
    "                    break\n",
    "                else: \n",
    "                    newList.append(token)\n",
    "                    break\n",
    "    return(newList)\n",
    "\n",
    "#Takes in a list of words to normalise. All stopwords are removed\n",
    "def stopwordNormalise (tokenList):\n",
    "    newList = list()\n",
    "    stops = set(stopwords.words('english'))\n",
    "    for x in tokenList:\n",
    "        if x not in stops:\n",
    "            newList.append(x)\n",
    "    return(newList)\n",
    "\n",
    "#Takes in a list of words to normalise. All words are returned in lower case form\n",
    "def caseNormalise (tokenList):\n",
    "    newList = list()\n",
    "    for x in tokenList:\n",
    "        newList.append(x.lower())\n",
    "    return(newList)\n",
    "        \n",
    "#Takes in a list of words to normalise. A list is returned with all the words with all the punctuation removed\n",
    "def punctuationNormalise (tokenList):\n",
    "    newList = list()\n",
    "    for x in tokenList:\n",
    "        if x not in string.punctuation:\n",
    "            newList.append(x)\n",
    "    return(newList)\n",
    "    \n",
    "#Returns the input list after it has been normalised\n",
    "def normalise (tokenList):\n",
    "    return punctuationNormalise(numberNormalise(caseNormalise(stopwordNormalise(tokenList))))\n",
    "\n",
    "#Takes the frequency distribution of words in all documents and returns the difference of word occurances between positive and negative reviews\n",
    "def set_frequency_difference(AllDocFreqDist):\n",
    "    #creates a separate frequency distribution for pos and neg reviews\n",
    "    pos_freq_dist=FreqDist()\n",
    "    neg_freq_dist=FreqDist()\n",
    "    my_pos_word_list = []\n",
    "    my_neg_word_list = []\n",
    "    FreqDiff = list()\n",
    "    pos_freq_diff = list()\n",
    "    neg_freq_diff = list()\n",
    "    \n",
    "    for reviewDist,label in AllDocFreqDist:\n",
    "        if label=='pos':\n",
    "            pos_freq_dist+=reviewDist\n",
    "        else:\n",
    "            neg_freq_dist+=reviewDist    \n",
    "    \n",
    "    for word in pos_freq_dist:\n",
    "        if word in neg_freq_dist:\n",
    "            diff = pos_freq_dist[word]-neg_freq_dist[word]\n",
    "            if diff>0:\n",
    "                tempTuple = word, diff\n",
    "                pos_freq_diff.append(tempTuple)\n",
    "    for word in neg_freq_dist:\n",
    "        if word in pos_freq_dist:\n",
    "            diff = neg_freq_dist[word]-pos_freq_dist[word]\n",
    "            if diff>0:\n",
    "                tempTuple = word, diff\n",
    "                neg_freq_diff.append(tempTuple)\n",
    "    \n",
    "    pos_freq_diff.sort(key=lambda a:a[1], reverse = True)\n",
    "    neg_freq_diff.sort(key=lambda a:a[1], reverse = True)\n",
    "    return pos_freq_diff, neg_freq_diff\n",
    "\n",
    "#returns the most frequent words from a word distribution\n",
    "def most_frequent_words(FreqDist, k):\n",
    "    returnList = list()\n",
    "    count = 0\n",
    "    for word, freq in FreqDist:\n",
    "        if count >= k:\n",
    "            break;\n",
    "        returnList.append(word)\n",
    "        count = count+1\n",
    "    return returnList\n",
    "    \n",
    "AllDocFreqDist = list()\n",
    "count=0\n",
    "for element in training_data:\n",
    "    newList = training_data[count][0]\n",
    "    DocFreqDist = FreqDist(normalise(newList))\n",
    "    DocTuple = (DocFreqDist, training_data[count][1])\n",
    "    AllDocFreqDist.append(DocTuple)\n",
    "    count+=1\n",
    "    \n",
    "pos_words, neg_words = set_frequency_difference(AllDocFreqDist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['film', 'life', 'also', 'well', 'best', 'great', 'many', 'story', 'world', 'films']\n"
     ]
    }
   ],
   "source": [
    "positive_words = most_frequent_words(pos_words, 10)\n",
    "print(positive_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['movie', 'bad', 'plot', 'get', 'worst', 'nothing', 'supposed', 'boring', 'stupid', 'script']\n"
     ]
    }
   ],
   "source": [
    "negative_words = most_frequent_words(neg_words, 10)\n",
    "print(negative_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have created several funtions in order to normalise the words in the documents (reviews). I then created a frequency distribution for each document. Each frequency distribution is then sorted into two lists (one for positive reviews and the other for negative reviews).\n",
    "\n",
    "After they are sorted, a frequency distribution is created for all words that appear in positive reviews. Another is created for all words that appear in negative reviews. These two are then compared. Two lists of tuples are created, one for positive words and one for negative words. Each tuple contains a word that appears in a positive and/or negative review and the number of times that it appears in one type of review over the other. Each tuple in the positive list of tuples contains a word that appears more in positive reviews than negative reviews and how many more thimes this is the case. This is the opposite for negative reviews. e.g. (\"film\", 680). This means that the word film appears in positive reviews 680 more times than it does in the negative reviews. \n",
    "Each list if then sorted from most occurances to fewest occurances.\n",
    "\n",
    "To get a list of the most k used words in either positive or negative reviews, the function \"most_frequent_words\" is used. It returns a list of the first 'k' words in the tuple list (where 'k' is the number of words to be returned). \n",
    "\n",
    "\n",
    "The numberNormalise function normalises all numbers that are passed into it. Numbers get turned into \"NUM\" and positions e.g. \"1st\" are changed into \"Nth\"\n",
    "The stopwordNormalise function removes stop words from the list of words input\n",
    "The caseNormalise function returns all words inputted as lower case\n",
    "The punctuationNormalise function removes punctuation\n",
    "The normalise function calls the above functions. This makes the code easier to read as one function can be called in-line (during the code) instead of several\n",
    "The set_frequency_difference function takes the frequency distribution of words in all documents and returns the difference of word occurances between positive and negative reviewsTakes the frequency distribution of words in all documents and returns the difference of word occurances between positive and negative reviews\n",
    "The most_frequent_words returns the most frequent words from a word distributionreturns the most frequent words from a word distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TApOQE6vND20"
   },
   "source": [
    "2) \n",
    "a) **Use** the lists generated in Q1 to build a **word list classifier** which will classify reviews as being positive or negative.\n",
    "\n",
    "b) **Explain** what you have done.\n",
    "\n",
    "[12.5\\%]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "BThDMrcmODJy"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "429\n",
      "171\n"
     ]
    }
   ],
   "source": [
    "#Takes in the documents, the positive word list and the negative word list and, based on whether there are more positive or negative occurances of words, classifies them as being positive or negative\n",
    "def classify_documents(documents, pos_words, neg_words):\n",
    "    pos_doc_list = list()\n",
    "    neg_doc_list = list()\n",
    "    for document in documents:\n",
    "        pos_count = 0\n",
    "        neg_count = 0\n",
    "        freqDist = FreqDist(normalise(document[0]))\n",
    "        for word in freqDist:\n",
    "            if word in pos_words:\n",
    "                pos_count = pos_count + freqDist[word]\n",
    "            if word in neg_words:\n",
    "                neg_count = neg_count + freqDist[word]\n",
    "        if pos_count > neg_count:\n",
    "            doc_class = [\"pos\"]\n",
    "        elif neg_count > pos_count:\n",
    "            doc_class = [\"neg\"]\n",
    "        else:\n",
    "            doc_class = [\"pos\", \"neg\"]\n",
    "        if random.choice(doc_class) == \"pos\":\n",
    "            documentTuple = (document, \"pos\")\n",
    "            pos_doc_list.append(document)\n",
    "        else:\n",
    "            documentTuple = (document, \"neg\")\n",
    "            neg_doc_list.append(document)                \n",
    "    return pos_doc_list, neg_doc_list\n",
    "\n",
    "pos_doc_list, neg_doc_list = classify_documents(testing_data, most_frequent_words(pos_words, 10), most_frequent_words(neg_words, 10))\n",
    "print(len(pos_doc_list))\n",
    "print(len(neg_doc_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I created a function that has an input of the testing data/the list of documents that need to be classified. For every document in the list of documents provided, this function normalises each document the list and creates a frequency distribution for it. Every word in the frequency distribution, is compared to the positive and negative word lists created in part 1. If the word being checked is in either word list, the frequency of that word is added to the respective count. After all words in review have been check, the review type of review (\"pos\" or \"neg\") gets added to the \"doc_class\" list (depending on which count is highest). If the counts are the same, the both get added to the list. From this list a random label is chosen and assigned to the document and the document is added to a list of only that label type (if only one label is in the list, only 1 can be chosen). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3)\n",
    "a) **Calculate** the accuracy, precision, recall and F1 score of your classifier.\n",
    "\n",
    "b) Is it reasonable to evaluate the classifier in terms of its accuracy?  **Explain** your answer and give a counter-example (a scenario where it would / would not be reasonable to evaluate the classifier in terms of its accuracy).\n",
    "\n",
    "[20\\%]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "261 168 132 39\n"
     ]
    }
   ],
   "source": [
    "#Takes in the positive and negative list of documents and counts how hamny are correctly and incorrectly sorted\n",
    "def sort_correctness(pos_list, neg_list, data = testing_data):\n",
    "    TP = 0\n",
    "    FP = 0\n",
    "    TN = 0\n",
    "    FN = 0\n",
    "    for review in data:\n",
    "        if review[1] == \"pos\":\n",
    "            if review in pos_list:\n",
    "                TP = TP+1\n",
    "            else:\n",
    "                FN = FN+1\n",
    "        else:\n",
    "            if review in neg_list:\n",
    "                TN = TN+1\n",
    "            else:\n",
    "                FP = FP+1\n",
    "    return TP, FP, TN, FN\n",
    "\n",
    "#Takes in the True Positives (TP), True Negatives (TN), False Positives (FP) and False Negatives (FN) and returns the accuracy of the classifier\n",
    "def calculate_accuracy(TP, FP, TN, FN):\n",
    "    return ((TP+TN)/(TP+FP+TN+FN))\n",
    "\n",
    "#Takes in the True Positives (TP), True Negatives (TN), False Positives (FP) and False Negatives (FN) and returns the precision of the classifier\n",
    "def calculate_precision(TP, FP, TN, FN):\n",
    "    return (TP/(TP+FP))\n",
    "\n",
    "#Takes in the True Positives (TP), True Negatives (TN), False Positives (FP) and False Negatives (FN) and returns the recall of the classifier\n",
    "def calculate_recall(TP, FP, TN, FN):\n",
    "    return (TP/(TP+FN))\n",
    "\n",
    "#Takes in the True Positives (TP), True Negatives (TN), False Positives (FP) and False Negatives (FN) and returns the F1 score of the classifier\n",
    "def calculate_F1_score(TP, FP, TN, FN):\n",
    "    return ((2*calculate_precision(TP, FP, TN, FN)*calculate_recall(TP, FP, TN, FN))/((calculate_precision(TP, FP, TN, FN))+calculate_recall(TP, FP, TN, FN)))\n",
    "\n",
    "TP, FP, TN, FN = sort_correctness(pos_doc_list, neg_doc_list)\n",
    "print(TP, FP, TN, FN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.655\n",
      "Precision:  0.6083916083916084\n",
      "Recall:  0.87\n",
      "F1 score:  0.7160493827160495\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy: \", calculate_accuracy(TP, FP, TN, FN))\n",
    "print(\"Precision: \", calculate_precision(TP, FP, TN, FN))\n",
    "print(\"Recall: \", calculate_recall(TP, FP, TN, FN))\n",
    "print(\"F1 score: \", calculate_F1_score(TP, FP, TN, FN))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The sort_correctness function counts and returns the True Positives (TP), True Negatives (TN), False Positives (FP) and False Negatives (FN) of the classifier\n",
    "The 'calculate' functions then use these values to return their respective values\n",
    "\n",
    "It is not always a good idea to judge the effectiveness of a classifier based on it's accuracy.\n",
    "While accuracy is a good measure of how well a classifier works with a balanced data set, if the data set is skewed the effectiveness decreases. If the data set is skewed and the classifier has a bias to it and the bias and the skew are in the same direction then the classifier would seem like it is working very accurately when in reality it may be guessing what class the data belongs in. \n",
    "As the guesses would follow the bias, it would appear to be working well. e.g. if 90% of the data inputted is negative and the classifier was guessing if pieces of data were positive or negative with a negative bias (e.g. only guessing negative), the classifier may receive a high level of accuracy (as only 10% would be classed wrong). If you were to use this same classifier with a balanced data set, the accuracy would likely be very poor.\n",
    "Due to this, accuracy is only effective with balanced data sets. This is a problem though as you cannot rely on having a balanced data set when using the classifier properly (not with training/testing data).\n",
    "\n",
    "Because of this, precision, recall and F1-score are a much better way of telling a classifiers effectiveness"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LIS9UpmJNEAp"
   },
   "source": [
    "4) \n",
    "a)  **Construct** a Naive Bayes classifier (e.g., from NLTK).\n",
    "\n",
    "b)  **Compare** the performance of your word list classifier with the Naive Bayes classifier.  **Discuss** your results. \n",
    "\n",
    "[12.5\\%]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.probability import FreqDist\n",
    "\n",
    "#Returns the probability that the training data has positive or negative labels\n",
    "def prob_of_positive(pos_docs, neg_docs):\n",
    "    total = len(pos_docs)+len(neg_docs)\n",
    "    return (len(pos_docs)/total)\n",
    "\n",
    "#Returns the probability of each word in a given frequency distribution \n",
    "def prob_of_words(freq_dist):\n",
    "    word_prob = list()\n",
    "    total = len(freq_dist)\n",
    "    for word, freq in freq_dist:\n",
    "        prob = freq / total\n",
    "        prob_tuple = (word, prob)\n",
    "        word_prob.append(prob_tuple)\n",
    "    return word_prob\n",
    "    \n",
    "#Takes a list of mixed \"pos\" and \"neg\" documents and returns two lists, one of \"pos\" documents and the other of \"neg\" documents\n",
    "def split_pos_neg(documents):\n",
    "    pos_docs = list()\n",
    "    neg_docs = list()\n",
    "    for document in documents:\n",
    "        if document[1] == \"pos\":\n",
    "            pos_docs.append(document)\n",
    "        else:\n",
    "            neg_docs.append(document)\n",
    "    return pos_docs, neg_docs\n",
    "\n",
    "#Returns the frequency distribution of all words across all documents \n",
    "def frequency_distribution_in_documents(documents):\n",
    "    docs_freq_dist = list()\n",
    "    for document, label in documents:\n",
    "        normalDoc = normalise(document)\n",
    "        freqDist = FreqDist(normalDoc)\n",
    "        docs_freq_dist.append(freqDist)\n",
    "    return docs_freq_dist\n",
    "\n",
    "#Performs the bayes calculation on each documents that is inputted and then assigns a class based on the answer\n",
    "def calculate_bayes(document, word_prob_list, class_prob_tuple):\n",
    "    pos_words = []\n",
    "    neg_words = []\n",
    "    for prob, label in word_prob_list:\n",
    "        if label == \"pos\":\n",
    "            pos_words.append(prob)\n",
    "        else:\n",
    "            neg_words.append(prob)\n",
    "    pos_class = class_prob_tuple[0]\n",
    "    neg_class = class_prob_tuple[1]\n",
    "    pos_prob = pos_class\n",
    "    neg_prob = neg_class\n",
    "    \n",
    "    for word in document:\n",
    "        changed = False\n",
    "        for word_prob, label in word_prob_list:\n",
    "            #print(\"\\n\\nword: \", word, \"\\nlabel: \", label, \"\\nprobability: \", word_prob)\n",
    "            if word == word_prob[0]:\n",
    "                #print(\"words match\")\n",
    "                if label == \"pos\":\n",
    "                    #print(\"label is pos\")\n",
    "                    pos_prob = pos_prob*(word_prob[1]*pos_class)\n",
    "                    changed = True\n",
    "                   # print(\"changed: \", changed)\n",
    "                    break\n",
    "            if word == word_prob[0]:\n",
    "                #print(\"words match\")\n",
    "                if label == \"neg\":\n",
    "                    #print(\"label is neg\")\n",
    "                    neg_prob = neg_prob*(word_prob[1]*neg_class)\n",
    "                    changed = True\n",
    "                    #print(\"changed: \", changed)\n",
    "                    break\n",
    "            \n",
    "    if pos_prob > neg_prob:\n",
    "        class_prob = {\"pos\": pos_prob}\n",
    "    if neg_prob > pos_prob:\n",
    "        class_prob = {\"pos\": pos_prob}\n",
    "    else:\n",
    "        class_prob = {\"pos\": pos_prob, \"neg\":neg_prob}\n",
    "    classes=list(class_prob.keys())\n",
    "    return random.choice(classes)\n",
    "\n",
    "#Performs the naive bayes calculation on all documents \n",
    "def naive_bayes_calculation(docs, freq_dist_tuple, pos_prob):\n",
    "    documents = list()\n",
    "    pos_docs = list()\n",
    "    neg_docs = list()\n",
    "    word_prob = list()\n",
    "\n",
    "    for each in prob_of_words(freq_dist_tuple[0]):\n",
    "        prob_tuple = (each, \"pos\")\n",
    "        word_prob.append(prob_tuple)\n",
    "    for each in prob_of_words(freq_dist_tuple[1]):\n",
    "        prob_tuple = (each, \"neg\")\n",
    "        word_prob.append(prob_tuple)\n",
    "    class_prob_tuple = (pos_prob, (1-pos_prob))\n",
    "    for document in docs:\n",
    "        documents.append(normalise(document[0]))\n",
    "    doc_tuples = list()\n",
    "    for document in documents:\n",
    "        doc_class = calculate_bayes(document, word_prob, class_prob_tuple)\n",
    "        doc_tuple = (document, doc_class)\n",
    "        doc_tuples.append(doc_tuple)\n",
    "    return doc_tuples\n",
    "\n",
    "pos_docs, neg_docs = split_pos_neg(testing_data)\n",
    "freq_dist_tuple = (pos_words, neg_words)\n",
    "docs_tuple = (pos_docs, neg_docs)\n",
    "\n",
    "classified_docs=naive_bayes_calculation(testing_data, freq_dist_tuple, prob_of_positive(pos_docs, neg_docs))\n",
    "\n",
    "#This part of the code is used to count the number of True Positives (TP), True Negatives (TN), False Positives (FP) and False Negatives (FN). This part of the code does not work\n",
    "TP = 0\n",
    "TN = 0\n",
    "FP = 0\n",
    "FN = 0\n",
    "\n",
    "for document, label in classified_docs:\n",
    "    for review in testing_data:\n",
    "        normal_review = normalise(review[0])\n",
    "        if normal_review == document:\n",
    "            if review[1] == \"pos\":\n",
    "                if label == \"pos\":\n",
    "                    TP = TP+1\n",
    "                else:\n",
    "                    FN = FN+1\n",
    "            if review[1] == \"neg\":\n",
    "                if label == \"neg\":\n",
    "                    TN = TN+1\n",
    "                else:\n",
    "                    FP = FP+1\n",
    "print(TP, FP, TN, FN)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy: \", calculate_accuracy(TP, FP, TN, FN))\n",
    "print(\"Precision: \", calculate_precision(TP, FP, TN, FN))\n",
    "print(\"Recall: \", calculate_recall(TP, FP, TN, FN))\n",
    "print(\"F1 score: \", calculate_F1_score(TP, FP, TN, FN))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the code above, documents get sorted into positive and negative with a naive bayes approach. The probability of a positive and negative review being chosen at random is calculated at. The probability that a given word is in a given type of review is also calculated (the frequency of that word divided by the total number of words in all reviews of that type). These two values are then multiplied together to give a probability of that word being in in a document of a given class. This probability is then built upon, until all words in the document have been reached, by being multiplied by the next words' probability that it is in the same given class.\n",
    "\n",
    "After this has been completed for both positive and negative classes, a class is assigned to the document. This is done by having the class with the highest probability being added to \"class_prob\". If both classes have the same probability, they are both added. From this, a random class is chosen and assigned.\n",
    "\n",
    "The number of True Positives (TP), True Negatives (TN), False Positives (FP) and False Negatives (FN) is then calculated along with the accuracy, precision, recall and F1 score\n",
    "\n",
    "\n",
    "The prob_of_positive function returns the probability that the training data has positive or negative labels. It takes the positive and negative document lists and outputs the probability that a document chosen at random is positive.\n",
    "The prob_of_words function returns the probability of each word in a given frequency distribution. It add the total number of frequencies in the frequency distribution and divides each frequency by this total.\n",
    "The split_pos_neg function takes a list of mixed \"pos\" and \"neg\" documents and returns two lists, one of \"pos\" documents and the other of \"neg\" documents. This is to then be fed into the prob_of_positive function.\n",
    "The frequency_distribution_in_documents function returns the frequency distribution of all words across all documents. It goes through each document and adds the words' frequencies to the running total (\"docs_freq_dist\").\n",
    "The calculate_bayes function performs the bayes calculation on each documents that is inputted and then assigns a class based on the answer. Whichever value is larger (probability that a document is positive, probability that a document in negative) gets added to \"class_prob\". A key from \"class_prob\" is chosen at random to be the label of the document.\n",
    "The naive_bayes_calculation function performs the calculate_bayes function on all documents."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LGDXaVDqOSfY"
   },
   "source": [
    "5) \n",
    "a) Design and **carry out an experiment** into the impact of the **length of the wordlists** on the wordlist classifier.  Make sure you **describe** design decisions in your experiment, include a **graph** of your results and **discuss** your conclusions. \n",
    "\n",
    "b) Would you **recommend** a wordlist classifier or a Naive Bayes classifier for future work in this area?  **Justify** your answer.\n",
    "\n",
    "[25\\%]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initial hypothesis: The larger the world list are, the longer it will take to classify each document but documents will be classified more accurately. To measure this, I will use the value for the True Positives (TP), True Negatives (TN), False Positives (FP) and False Negatives (FN). To measure the time taken, the time library will be used. I will then plot an accuracy, precision, recall and F1 score graph as well as a time taken to classify at with each word list length graph and an F1 score per second graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "AllDocFreqDist = list()\n",
    "count=0\n",
    "for element in training_data:\n",
    "    newList = training_data[count][0]\n",
    "    normalList = normalise(newList)\n",
    "    DocFreqDist = FreqDist(normalList)\n",
    "    DocTuple = (DocFreqDist, training_data[count][1])\n",
    "    AllDocFreqDist.append(DocTuple)\n",
    "    count+=1\n",
    "pos_words, neg_words = set_frequency_difference(AllDocFreqDist)\n",
    "\n",
    "#Word list length 10, creation, classification and correctness\n",
    "pos10 = most_frequent_words(pos_words, 10)\n",
    "neg10 = most_frequent_words(neg_words, 10)\n",
    "start_time = time.time()\n",
    "pos_doc_list, neg_doc_list = classify_documents(testing_data, pos10, neg10)\n",
    "classify_time10 = (time.time() - start_time)\n",
    "print(\"\\n10 word classifier took: \", classify_time10)\n",
    "TP, FP, TN, FN = sort_correctness(pos_doc_list, neg_doc_list)\n",
    "correctness_10 = (TP, FP, TN, FN)\n",
    "\n",
    "#Word list length 20, creation, classification and correctness\n",
    "pos20 = most_frequent_words(pos_words, 20)\n",
    "neg20 = most_frequent_words(neg_words, 20)\n",
    "start_time = time.time()\n",
    "pos_doc_list, neg_doc_list = classify_documents(testing_data, pos20, neg20)\n",
    "classify_time20 = (time.time() - start_time)\n",
    "print(\"\\n20 word classifier took: \", classify_time20)\n",
    "TP, FP, TN, FN = sort_correctness(pos_doc_list, neg_doc_list)\n",
    "correctness_20 = (TP, FP, TN, FN)\n",
    "\n",
    "#Word list length 30, creation, classification and correctness\n",
    "pos30 = most_frequent_words(pos_words, 30)\n",
    "neg30 = most_frequent_words(neg_words, 30)\n",
    "start_time = time.time()\n",
    "pos_doc_list, neg_doc_list = classify_documents(testing_data, pos30, neg30)\n",
    "classify_time30 = (time.time() - start_time)\n",
    "print(\"\\n30 word classifier took: \", classify_time30)\n",
    "TP, FP, TN, FN = sort_correctness(pos_doc_list, neg_doc_list)\n",
    "correctness_30 = (TP, FP, TN, FN)\n",
    "\n",
    "#Word list length 40, creation, classification and correctness\n",
    "pos40 = most_frequent_words(pos_words, 40)\n",
    "neg40 = most_frequent_words(neg_words, 40)\n",
    "start_time = time.time()\n",
    "pos_doc_list, neg_doc_list = classify_documents(testing_data, pos40, neg40)\n",
    "classify_time40 = (time.time() - start_time)\n",
    "print(\"\\n40 word classifier took: \", classify_time40)\n",
    "TP, FP, TN, FN = sort_correctness(pos_doc_list, neg_doc_list)\n",
    "correctness_40 = (TP, FP, TN, FN)\n",
    "\n",
    "#Word list length 50, creation, classification and correctness\n",
    "pos50 = most_frequent_words(pos_words, 50)\n",
    "neg50 = most_frequent_words(neg_words, 50)\n",
    "start_time = time.time()\n",
    "pos_doc_list, neg_doc_list = classify_documents(testing_data, pos50, neg50)\n",
    "classify_time50 = (time.time() - start_time)\n",
    "print(\"\\n50 word classifier took: \", classify_time50)\n",
    "TP, FP, TN, FN = sort_correctness(pos_doc_list, neg_doc_list)\n",
    "correctness_50 = (TP, FP, TN, FN)\n",
    "\n",
    "#Word list length 60, creation, classification and correctness\n",
    "pos60 = most_frequent_words(pos_words, 60)\n",
    "neg60 = most_frequent_words(neg_words, 60)\n",
    "start_time = time.time()\n",
    "pos_doc_list, neg_doc_list = classify_documents(testing_data, pos60, neg60)\n",
    "classify_time60 = (time.time() - start_time)\n",
    "print(\"\\n60 word classifier took: \", classify_time60)\n",
    "TP, FP, TN, FN = sort_correctness(pos_doc_list, neg_doc_list)\n",
    "correctness_60 = (TP, FP, TN, FN)\n",
    "\n",
    "#Word list length 70, creation, classification and correctness\n",
    "pos70 = most_frequent_words(pos_words, 70)\n",
    "neg70 = most_frequent_words(neg_words, 70)\n",
    "start_time = time.time()\n",
    "pos_doc_list, neg_doc_list = classify_documents(testing_data, pos70, neg70)\n",
    "classify_time70 = (time.time() - start_time)\n",
    "print(\"\\n70 word classifier took: \", classify_time70)\n",
    "TP, FP, TN, FN = sort_correctness(pos_doc_list, neg_doc_list)\n",
    "correctness_70 = (TP, FP, TN, FN)\n",
    "\n",
    "#Word list length 80, creation, classification and correctness\n",
    "pos80 = most_frequent_words(pos_words, 80)\n",
    "neg80 = most_frequent_words(neg_words, 80)\n",
    "start_time = time.time()\n",
    "pos_doc_list, neg_doc_list = classify_documents(testing_data, pos80, neg80)\n",
    "classify_time80 = (time.time() - start_time)\n",
    "print(\"\\n80 word classifier took: \", classify_time80)\n",
    "TP, FP, TN, FN = sort_correctness(pos_doc_list, neg_doc_list)\n",
    "correctness_80 = (TP, FP, TN, FN)\n",
    "\n",
    "#Word list length 90, creation, classification and correctness\n",
    "pos90 = most_frequent_words(pos_words, 90)\n",
    "neg90 = most_frequent_words(neg_words, 90)\n",
    "start_time = time.time()\n",
    "pos_doc_list, neg_doc_list = classify_documents(testing_data, pos90, neg90)\n",
    "classify_time90 = (time.time() - start_time)\n",
    "print(\"\\n90 word classifier took: \", classify_time90)\n",
    "TP, FP, TN, FN = sort_correctness(pos_doc_list, neg_doc_list)\n",
    "correctness_90 = (TP, FP, TN, FN)\n",
    "\n",
    "#Word list length 100, creation, classification and correctness\n",
    "pos100 = most_frequent_words(pos_words, 100)\n",
    "neg100 = most_frequent_words(neg_words, 100)\n",
    "start_time = time.time()\n",
    "pos_doc_list, neg_doc_list = classify_documents(testing_data, pos100, neg100)\n",
    "classify_time100 = (time.time() - start_time)\n",
    "print(\"\\n100 word classifier took: \", classify_time100)\n",
    "TP, FP, TN, FN = sort_correctness(pos_doc_list, neg_doc_list)\n",
    "correctness_100 = (TP, FP, TN, FN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {\"Accuracy\":{\"10\":calculate_accuracy(correctness_10[0], correctness_10[1], correctness_10[2], correctness_10[3]), \"20\":calculate_accuracy(correctness_20[0], correctness_20[1], correctness_20[2], correctness_20[3]), \"30\":calculate_accuracy(correctness_30[0], correctness_30[1], correctness_30[2], correctness_30[3]), \"40\":calculate_accuracy(correctness_40[0], correctness_40[1], correctness_40[2], correctness_40[3]), \"50\":calculate_accuracy(correctness_50[0], correctness_50[1], correctness_50[2], correctness_50[3]), \"60\":calculate_accuracy(correctness_60[0], correctness_60[1], correctness_60[2], correctness_60[3]), \"70\":calculate_accuracy(correctness_70[0], correctness_70[1], correctness_70[2], correctness_70[3]), \"80\":calculate_accuracy(correctness_80[0], correctness_80[1], correctness_80[2], correctness_80[3]), \"90\":calculate_accuracy(correctness_90[0], correctness_90[1], correctness_90[2], correctness_90[3]), \"100\":calculate_accuracy(correctness_100[0], correctness_100[1], correctness_100[2], correctness_100[3])}, \"Precision\":{\"10\":calculate_precision(correctness_10[0], correctness_10[1], correctness_10[2], correctness_10[3]), \"20\":calculate_precision(correctness_20[0], correctness_20[1], correctness_20[2], correctness_20[3]), \"30\":calculate_precision(correctness_30[0], correctness_30[1], correctness_30[2], correctness_30[3]), \"40\":calculate_precision(correctness_40[0], correctness_40[1], correctness_40[2], correctness_40[3]), \"50\":calculate_precision(correctness_50[0], correctness_50[1], correctness_50[2], correctness_50[3]), \"60\":calculate_precision(correctness_60[0], correctness_60[1], correctness_60[2], correctness_60[3]), \"70\":calculate_precision(correctness_70[0], correctness_70[1], correctness_70[2], correctness_70[3]), \"80\":calculate_precision(correctness_80[0], correctness_80[1], correctness_80[2], correctness_80[3]), \"90\":calculate_precision(correctness_90[0], correctness_90[1], correctness_90[2], correctness_90[3]), \"100\":calculate_precision(correctness_100[0], correctness_100[1], correctness_100[2], correctness_100[3])}, \"Recall\":{\"10\":calculate_recall(correctness_10[0], correctness_10[1], correctness_10[2], correctness_10[3]), \"20\":calculate_recall(correctness_20[0], correctness_20[1], correctness_20[2], correctness_20[3]), \"30\":calculate_recall(correctness_30[0], correctness_30[1], correctness_30[2], correctness_30[3]), \"40\":calculate_recall(correctness_40[0], correctness_40[1], correctness_40[2], correctness_40[3]), \"50\":calculate_recall(correctness_50[0], correctness_50[1], correctness_50[2], correctness_50[3]), \"60\":calculate_recall(correctness_60[0], correctness_60[1], correctness_60[2], correctness_60[3]), \"70\":calculate_recall(correctness_70[0], correctness_70[1], correctness_70[2], correctness_70[3]), \"80\":calculate_recall(correctness_80[0], correctness_80[1], correctness_80[2], correctness_80[3]), \"90\":calculate_recall(correctness_90[0], correctness_90[1], correctness_90[2], correctness_90[3]), \"100\":calculate_recall(correctness_100[0], correctness_100[1], correctness_100[2], correctness_100[3])}, \"F1_score\":{\"10\":calculate_F1_score(correctness_10[0], correctness_10[1], correctness_10[2], correctness_10[3]), \"20\":calculate_F1_score(correctness_20[0], correctness_20[1], correctness_20[2], correctness_20[3]), \"30\":calculate_F1_score(correctness_30[0], correctness_30[1], correctness_30[2], correctness_30[3]), \"40\":calculate_F1_score(correctness_40[0], correctness_40[1], correctness_40[2], correctness_40[3]), \"50\":calculate_F1_score(correctness_50[0], correctness_50[1], correctness_50[2], correctness_50[3]), \"60\":calculate_F1_score(correctness_60[0], correctness_60[1], correctness_60[2], correctness_60[3]), \"70\":calculate_F1_score(correctness_70[0], correctness_70[1], correctness_70[2], correctness_70[3]), \"80\":calculate_F1_score(correctness_80[0], correctness_80[1], correctness_80[2], correctness_80[3]), \"90\":calculate_F1_score(correctness_90[0], correctness_90[1], correctness_90[2], correctness_90[3]), \"100\":calculate_F1_score(correctness_100[0], correctness_100[1], correctness_100[2], correctness_100[3])}}\n",
    "correctness = pd.DataFrame(results)\n",
    "correctness_graph = correctness.plot(kind=\"line\",title=\"Experiment Results\")\n",
    "correctness_graph.set_ylabel(\"Score\")\n",
    "correctness_graph.set_xlabel(\"Word List Size\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "times = {\"Classify time\":{\"10\":classify_time10, \"20\":classify_time20, \"30\":classify_time30, \"40\":classify_time40, \"50\":classify_time50, \"60\":classify_time60, \"70\":classify_time70, \"80\":classify_time80, \"90\":classify_time90, \"100\":classify_time100}}\n",
    "exp_times = pd.DataFrame(times)\n",
    "times_graph = exp_times.plot(kind=\"line\",title=\"Time to classify Results\")\n",
    "times_graph.set_ylabel(\"Time Taken (s)\")\n",
    "times_graph.set_xlabel(\"Word List Size\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_f1_ratio = {\"Time/F1 Score\":{\"10\":calculate_F1_score(correctness_10[0], correctness_10[1], correctness_10[2], correctness_10[3])/classify_time10, \"20\":calculate_F1_score(correctness_20[0], correctness_20[1], correctness_20[2], correctness_20[3])/classify_time20, \"30\":calculate_F1_score(correctness_30[0], correctness_30[1], correctness_30[2], correctness_30[3])/classify_time30, \"40\":calculate_F1_score(correctness_40[0], correctness_40[1], correctness_40[2], correctness_40[3])/classify_time40, \"50\":calculate_F1_score(correctness_50[0], correctness_50[1], correctness_50[2], correctness_50[3])/classify_time50, \"60\":calculate_F1_score(correctness_60[0], correctness_60[1], correctness_60[2], correctness_60[3])/classify_time60, \"70\":calculate_F1_score(correctness_70[0], correctness_70[1], correctness_70[2], correctness_70[3])/classify_time70, \"80\":calculate_F1_score(correctness_80[0], correctness_80[1], correctness_80[2], correctness_80[3])/classify_time80, \"90\":calculate_F1_score(correctness_90[0], correctness_90[1], correctness_90[2], correctness_90[3])/classify_time90, \"100\":calculate_F1_score(correctness_100[0], correctness_100[1], correctness_100[2], correctness_100[3])/classify_time100}}\n",
    "time_f1 = pd.DataFrame(time_f1_ratio)\n",
    "time_f1_graph = time_f1.plot(kind=\"line\",title=\"F1 Score/Time Ratio\")\n",
    "time_f1_graph.set_ylabel(\"F1 Score Per Second\")\n",
    "time_f1_graph.set_xlabel(\"Word List Size\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this experiment we see what the effects of the length of the word list of a word list classifier has on the running time and correctness of a classifier.\n",
    "\n",
    "Ten word lists are created of differing lengths, from 10 to 100, in 10 word length increments. These values were chosen to provide a wide range. The fact that the largest result is 10 times larger than the small one allows us to see to what extent the values of the accuracy, precision, recall and F1 score change.\n",
    "\n",
    "For each word list, the time taken to classify the documents is taken and plotted. (see above)\n",
    "As well as this is a graph that states the accuracy, precision, recall and F1 score for each word list.\n",
    "\n",
    "Method:\n",
    "After all training documents are normalised and a frequency distributions of positive and negative words are created, the first N words are taken from each list. This N started at 10 and increased by 10 until word lists of 100 words were created. For each of the pairs of different length lists, the testing documents are classified. The time taken for each of these classifications is recorded as well as the number of true positives, true negatives, false positives and false negatives produced by each classification. From these values, the accuracy, precision, recall and F1 score is calculated and plotted. Another graph is produced with the time taken to classify documents given different length word lists."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b)\n",
    "As the word list grows the F1 score of the classifier and the time taken to classify increases. These two values, however, do not increase at the same rate. The time taken to classify increases at a faster rate. This means that the ratio between the amount of time taken to classify the documents and the F1 score gets worse the larger the word list length. Due to this, people should try to avoid word list classifiers for a large number of documents; the more documents you have, the larger the word list needs to be in order to minimise the amount of random choices made by the classifier.\n",
    "For very large data sets, a naive bayes classifier would produce similar (or better results) faster. Due to this, I would recommed a naive bayes classifer for larger data sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "executionInfo": {
     "elapsed": 946,
     "status": "ok",
     "timestamp": 1602228353024,
     "user": {
      "displayName": "Julie Weeds",
      "photoUrl": "",
      "userId": "13844540934373660130"
     },
     "user_tz": -60
    },
    "id": "34rdlS_iPov6",
    "outputId": "06237f84-098e-4c36-efc5-52ab25d68da5"
   },
   "outputs": [],
   "source": [
    "##This code will word count all of the markdown cells in the notebook saved at filepath\n",
    "##Running it before providing any answers shows that the questions have a word count of 437\n",
    "\n",
    "import io\n",
    "from nbformat import current\n",
    "\n",
    "#filepath=\"/content/drive/My Drive/NLE Notebooks/assessment/assignment1.ipynb\"\n",
    "filepath=\"NLassignment2021.ipynb\"\n",
    "question_count=437\n",
    "\n",
    "with io.open(filepath, 'r', encoding='utf-8') as f:\n",
    "    nb = current.read(f, 'json')\n",
    "\n",
    "word_count = 0\n",
    "for cell in nb.worksheets[0].cells:\n",
    "    if cell.cell_type == \"markdown\":\n",
    "        word_count += len(cell['source'].replace('#', '').lstrip().split(' '))\n",
    "print(\"Submission length is {}\".format(word_count-question_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PtqCcG6wPsmf"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNR6MWwZjzeJdfC3cJvdSQV",
   "name": "assignment1_SOLUTIONS.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
